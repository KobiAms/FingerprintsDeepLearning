{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Single Fingerprint Deep Classification**\n",
    "### **JCE - Software Engineering Final Project** \n",
    "##### ***By Kobi Amsellem & Zohar Kedem***\n",
    "\n",
    "##### In this study we want to discovare if Deep Convolutional Neural Network can classify single fingerprint image to find the owner: \n",
    "##### **1. Gender** - 2 classes (male/female).\n",
    "##### **2. Finger name** - 10 classes (right-thumb, ..., right-thumb, ...)\n",
    "##### **3. Fingerprint type** - 5 classes (left loop, whirl, right loop, tented arch, arch)\n",
    "##### **4. Same Person** - 2 classes (Same, Different) *(whether or not two fingerprints belong to the same personperson)* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import datasets as ds\n",
    "import FPMLmodule.utils as utils\n",
    "import tensorflow as tf\n",
    "import FPMLmodule.backbones as backbones\n",
    "import FPMLmodule.classifiers as classifiers\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop\n",
    "from FPMLmodule.fpml import FPML \n",
    "from pathlib import Path\n",
    "\n",
    "print('TensorFlow Version:', tf.__version__)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "dbStudyOutPath ='./out/{}/'\n",
    "\n",
    "weightsRN50 = \"./weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "weightsMNV2 = \"./weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\"\n",
    "weightsENB2 = \"./weights/efficientnetb2_notop.h5\"\n",
    "weightsINCEPTIONV3 = \"./weights/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "weightsXCEPTION = \"./weights/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Search** \n",
    "##### Main method to search after the best model\n",
    "\n",
    "in this section we define the ````researchBestModel````, a method to search and compare between several different models and hyper parameters and choose the best one for specific dataset.\n",
    "\n",
    "##### **Stages:**\n",
    "##### **1.** Backbone Transfer Learning mode comparison - (a) Pretraind wheights and Untrainable, (b) Pretraind wheights and Trainable, (c) Initialize wheight and Trainable.\n",
    "##### **2.** Loss function comparison. \n",
    "##### **3.** Learning rates comparison. \n",
    "##### **4.** Optimizers comparison. \n",
    "##### **5.** Backbone comparison. \n",
    "##### **6.** Train best configuration for extra epochs on train+validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def researchBestModel(configureDS, datasets, epochsSearch, epochsBest, path, optimizers, learningRates, defaultHypers, losses, defaultBackbone, backbonesForSearch, verbose=1):\n",
    "    \n",
    "    trainDs, testDs, valDs = datasets\n",
    "    imgDim = configureDS.inputDim\n",
    "    nbClasses = len(configureDS.classNames)\n",
    "    outFilePath = path + 'ablationHistory.csv'\n",
    "    \n",
    "    print('Ablation for', configureDS.name)\n",
    "    # --------------------------------------------------\n",
    "    # ---- Stage 1 - Compare Transfer Learning Mode ----\n",
    "    # --------------------------------------------------\n",
    "    trainingModeStudy =  {\n",
    "        'DNN-TransferLearningMode' : {\n",
    "            \"architecture\": {\n",
    "                \"backbone\": [\n",
    "                    defaultBackbone(imgDim, weights=weightsMNV2, trainable=False, name='PT&Untrainable'),\n",
    "                    defaultBackbone(imgDim, weights=weightsMNV2, trainable=True, name='PT&Trainable'),\n",
    "                    defaultBackbone(imgDim, weights=None, trainable=True, name='IN&Trainable')\n",
    "                    ],\n",
    "                \"classfier\": classifiers.DefaultClassifier(nbClasses, \"softmax\"),\n",
    "                \"inputLayer\": None, \n",
    "                \"inputDim\": imgDim\n",
    "            },\n",
    "            \"hyperparameters\":defaultHypers\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    trainingModeHistories = utils.researchStudies(trainDs, valDs, trainingModeStudy, epochsSearch, verbose)\n",
    "    bestTrainMode = utils.getBestStudyFromHistories(trainingModeHistories)\n",
    "    trainable = 'Trainable' in bestTrainMode\n",
    "    pretrained = 'PT' in bestTrainMode\n",
    "    utils.displayStudiesProgress(trainingModeHistories, path, 'Comparison Transfer Learning Mode')\n",
    "    utils.saveStudyHistory(trainingModeStudy, trainingModeHistories, outFilePath)\n",
    "    print(\"Backbone Transfer Learning Mode Selected - Pretrained:\", pretrained, 'Trainable:', trainable)\n",
    "\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # ---- Stage 2 - Compare Loss Functions ----\n",
    "    # ------------------------------------------\n",
    "    lossStudy = copy.deepcopy(trainingModeHistories[bestTrainMode]['config'])\n",
    "    lossStudy['hyperparameters'][\"loss\"] = losses\n",
    "    lossesHistories = utils.researchStudies(trainDs, valDs, {bestTrainMode: lossStudy}, epochsSearch, verbose)\n",
    "    lossesHistories[bestTrainMode+\"_\"+str(defaultHypers[\"loss\"])] = trainingModeHistories[bestTrainMode]\n",
    "    bestLoss = utils.getBestStudyFromHistories(lossesHistories)\n",
    "    utils.displayStudiesProgress(lossesHistories, path, 'Comparison Loss Functions')\n",
    "    utils.saveStudyHistory({'BestLoss': lossStudy}, lossesHistories, outFilePath)\n",
    "    print(\"Best Loss Function:\", str(lossesHistories[bestLoss]['config']['hyperparameters'][\"loss\"]))\n",
    "    \n",
    "    # ------------------------------------------\n",
    "    # ---- Stage 3 - Compare Learning Rates ----\n",
    "    # ------------------------------------------\n",
    "    learningRatesStudy = copy.deepcopy(lossesHistories[bestLoss]['config'])\n",
    "    learningRatesStudy['hyperparameters']['learningRate'] = learningRates\n",
    "    learningRatesHistories = utils.researchStudies(trainDs, valDs, {bestLoss: learningRatesStudy}, epochsSearch, verbose)\n",
    "    learningRatesHistories[bestLoss+\"_\"+str(defaultHypers[\"learningRate\"])] = lossesHistories[bestLoss]\n",
    "    bestLearningRate = utils.getBestStudyFromHistories(learningRatesHistories)\n",
    "    utils.displayStudiesProgress(learningRatesHistories, path, 'Comparison Learning Rate')\n",
    "    utils.saveStudyHistory({'BestLearningRate': learningRatesStudy}, learningRatesHistories, outFilePath)\n",
    "    print(\"Best Learning Rate:\", str(learningRatesHistories[bestLearningRate]['config'][\"hyperparameters\"][\"learningRate\"]))\n",
    "\n",
    "\n",
    "    # --------------------------------------\n",
    "    # ---- Stage 4 - Compare Optimizers ----\n",
    "    # --------------------------------------\n",
    "    optimizersStudy = copy.deepcopy(learningRatesHistories[bestLearningRate]['config'])\n",
    "    optimizersStudy[\"hyperparameters\"][\"optimizer\"] = optimizers\n",
    "    optimizersHistories = utils.researchStudies(trainDs, valDs, {bestLearningRate : optimizersStudy}, epochsSearch, verbose)\n",
    "    optimizersHistories[bestLearningRate+\"_\"+defaultHypers['optimizer'].__name__] = learningRatesHistories[bestLearningRate]\n",
    "    bestOptimizier = utils.getBestStudyFromHistories(optimizersHistories)\n",
    "    utils.displayStudiesProgress(optimizersHistories, path, 'Comparison Optimizer')\n",
    "    utils.saveStudyHistory({'BestOptimizier': optimizersStudy}, optimizersHistories, outFilePath)\n",
    "    print(\"Best Optimizier:\", optimizersHistories[bestOptimizier]['config'][\"hyperparameters\"][\"optimizer\"].__name__)\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------\n",
    "    # ---- Stage 5 - Compare DNN Backbones -----\n",
    "    # ------------------------------------------\n",
    "    backboneConfigs = [backbone['backbone'](imgDim, weights=backbone['weights'], trainable=trainable) for backbone in backbonesForSearch]\n",
    "    bestBackboneStudy = copy.deepcopy(optimizersHistories[bestOptimizier]['config'])\n",
    "    bestBackboneStudy[\"architecture\"][\"backbone\"] = backboneConfigs\n",
    "    bestBackboneHistories = utils.researchStudies(trainDs, valDs, {bestOptimizier: bestBackboneStudy}, epochsSearch, verbose)\n",
    "    bestBackboneHistories[bestOptimizier+\"_\"+defaultBackbone.__name__] = optimizersHistories[bestOptimizier]\n",
    "    bestBackbone = utils.getBestStudyFromHistories(bestBackboneHistories)\n",
    "    utils.displayStudiesProgress(bestBackboneHistories, path, 'Comparison DNN Backbone')\n",
    "    utils.saveStudyHistory({'BestBackbone': bestBackboneStudy}, bestBackboneHistories, outFilePath)\n",
    "    print(\"Best DNN Backbone:\", bestBackboneHistories[bestBackbone]['config'][\"architecture\"][\"backbone\"].name)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # ---- Stage 6 - Train Best model on train+validation -----\n",
    "    # ---------------------------------------------------------\n",
    "    bestModelConfiguration = bestBackboneHistories[bestBackbone]['config']\n",
    "    trainValDs = trainDs.concatenate(valDs)\n",
    "\n",
    "    bestModel = FPML(**bestModelConfiguration[\"architecture\"]).create(**bestModelConfiguration[\"hyperparameters\"])\n",
    "    bestModelHistory = bestModel.fit(trainValDs, validation_data=testDs, epochs=epochsBest, verbose=verbose)\n",
    "    toSave = {'Best Model':{'history' : bestModelHistory, 'config' : bestModelConfiguration}}\n",
    "    utils.displayStudiesProgress(toSave, path, 'Best Model')\n",
    "    utils.saveStudyHistory({'Best Model': bestModelConfiguration}, toSave, outFilePath)\n",
    "    utils.displayConfusion(testDs, bestModel, path)\n",
    "    \n",
    "    return bestModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Datasets Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetsConfig = {\n",
    "    'batchSize': 32, \n",
    "    'parallelTune': tf.data.AUTOTUNE, \n",
    "    'split': [0.7, 0.15, 0.15], \n",
    "    'inputDim': (224, 224, 3), \n",
    "    'seed': 9, \n",
    "    'shuffle': True\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Gender Study** \n",
    "##### **Datasets**\n",
    "* **SOCOFing**\n",
    "* **NIST Special Database 4**\n",
    "\n",
    "##### **Hyperparameters**\n",
    "* Optimizers: *Adam, Nadam, RMSprop*\n",
    "* Loss Functions: *binary-crossentropy, binary-focal-crossentropy, hinge*\n",
    "* Learning Rates: *0.1, 0.01, 0.001, 0.0001, 0.00001*\n",
    "* Backbones: *MobileNetV2, ResNet50, EfficientNetB2, InceptionV3, Xception*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderDatasets = [\n",
    "    ds.SOCOFingGender(**datasetsConfig, sampling=ds.SOCOFingGender.UNDER_SAMPLING),\n",
    "    ds.NISTSDB4Gender(**datasetsConfig)\n",
    "]\n",
    "\n",
    "GenderConfig = {\n",
    "    'defaultBackbone': backbones.MobileNetV2,\n",
    "    'defaultHypers': {\n",
    "        \"optimizer\": Adam,\n",
    "        \"learningRate\": 0.001,\n",
    "        \"loss\": 'binary_crossentropy',\n",
    "        \"metrics\": 'accuracy'\n",
    "    },\n",
    "    'losses': ['binary_focal_crossentropy', 'hinge'],\n",
    "    'learningRates': [0.1, 0.01, 0.0001, 0.00001],\n",
    "    'optimizers': [Nadam, RMSprop],\n",
    "    'backbonesForSearch': [\n",
    "        {'backbone' : backbones.ResNet50, 'weights' : weightsRN50},\n",
    "        {'backbone' : backbones.EfficientNetB2, 'weights' : weightsENB2},\n",
    "        {'backbone' : backbones.InceptionV3, 'weights' : weightsINCEPTIONV3},\n",
    "        {'backbone' : backbones.Xception, 'weights' : weightsXCEPTION}, \n",
    "    ],\n",
    "    'epochsSearch': 2,\n",
    "    'epochsBest': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "genderOutPath = dbStudyOutPath.format('Gender/{}')\n",
    "\n",
    "genderDatasetsPrepared = utils.prepareDatasetsForStudy(genderDatasets, genderOutPath) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Finger Name** \n",
    "##### **Datasets:**\n",
    "* **SOCOFing**\n",
    "* **NIST Special Database 4**\n",
    "* **NIST Special Database 300a Roll**\n",
    "* **NIST Special Database 300b - All Scanners**\n",
    "\n",
    "##### **Hyperparameters**\n",
    "* Optimizers: *Adam, Nadam, RMSprop*\n",
    "* Loss Functions: *categorical-crossentropy, mean-squared-error, categorical-hinge*\n",
    "* Learning Rates: *0.1, 0.01, 0.001, 0.0001, 0.00001*\n",
    "* Backbones: *MobileNetV2, ResNet50, EfficientNetB2, InceptionV3, Xception*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingersNameDatasets = [\n",
    "    ds.SOCOFingFingers(**datasetsConfig), \n",
    "    ds.NISTSDB4Fingers(**datasetsConfig), \n",
    "    ds.NISTSDB300aFingers(**datasetsConfig), \n",
    "    ds.NISTSDB302bFingers(**datasetsConfig)\n",
    "    ]\n",
    "\n",
    "fingerNameStudyParams = {\n",
    "    'defaultBackbone': backbones.MobileNetV2,\n",
    "    'defaultHypers': {\n",
    "        \"optimizer\": Adam,\n",
    "        \"learningRate\": 0.001,\n",
    "        \"loss\": 'categorical_crossentropy',\n",
    "        \"metrics\": 'accuracy'\n",
    "    },\n",
    "    'optimizers': [Nadam, RMSprop],\n",
    "    'learningRates': [0.1, 0.01, 0.0001, 0.00001],\n",
    "    'losses': ['mean_squared_error', 'categorical_hinge'],\n",
    "    'backbonesForSearch': [\n",
    "        {'backbone' : backbones.ResNet50, 'weights' : weightsRN50},\n",
    "        {'backbone' : backbones.EfficientNetB2, 'weights' : weightsENB2},\n",
    "        {'backbone' : backbones.InceptionV3, 'weights' : weightsINCEPTIONV3},\n",
    "        {'backbone' : backbones.Xception, 'weights' : weightsXCEPTION}, \n",
    "    ],\n",
    "    'epochsSearch': 5,\n",
    "    'epochsBest': 10,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "fingerOutPath = dbStudyOutPath.format('FingerName/{}')\n",
    "fingersDatasetsPrepared = utils.prepareDatasetsForStudy(fingersNameDatasets, fingerOutPath) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def researchStudy(preparedDatasets, studyParams):\n",
    "    bestModels = {}\n",
    "    for dsName, dsObj in preparedDatasets.items():\n",
    "        bestModels[dsName] = researchBestModel(**dsObj, **studyParams)\n",
    "    return bestModels\n",
    "        \n",
    "fingersBestModels = researchStudy(fingersDatasetsPrepared, fingerNameStudyParams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfmetal",
   "language": "python",
   "name": "tfmetal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
