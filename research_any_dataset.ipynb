{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Single Fingerprint Deep Classification**\n",
    "### **JCE - Software Engineering Final Project** \n",
    "##### ***By Kobi Amsellem & Zohar Kedem***\n",
    "\n",
    "##### In this study we want to discovare if Deep Convolutional Neural Network can classify single fingerprint image to find the owner: \n",
    "##### **1. Gender** - 2 classes (male/female).\n",
    "##### **2. Finger name** - 10 classes (right-thumb, ..., right-thumb, ...)\n",
    "##### **3. Fingerprint type** - 5 classes (left loop, whirl, right loop, tented arch, arch)\n",
    "##### **4. Same Person** - 2 classes (Same, Different) *(whether or not two fingerprints belong to the same personperson)* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import datasets as ds\n",
    "import tensorflow as tf\n",
    "import FPMLmodule.utils as utils\n",
    "import FPMLmodule.backbones as bb\n",
    "import FPMLmodule.classifiers as cf\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop\n",
    "from FPMLmodule.fpml import FPML \n",
    "from pathlib import Path\n",
    "\n",
    "print('TensorFlow Version:', tf.__version__)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "dbStudyOutPath ='./out/{}/'\n",
    "\n",
    "weightsRN50 = \"./weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "weightsMNV2 = \"./weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\"\n",
    "weightsENB2 = \"./weights/efficientnetb2_notop.h5\"\n",
    "weightsINCEPTIONV3 = \"./weights/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "weightsXCEPTION = \"./weights/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Search** \n",
    "##### Main method to search after the best model\n",
    "\n",
    "in this section we define the ````researchBestModel````, a method to search and compare between several different models and hyper parameters and choose the best one for specific dataset.\n",
    "\n",
    "##### **Stages:**\n",
    "##### **1.** Backbone Transfer Learning mode comparison - (a) Pretraind wheights and Untrainable, (b) Pretraind wheights and Trainable, (c) Initialize wheight and Trainable.\n",
    "##### **2.** Backbone comparison. \n",
    "##### **3.** Classifier (perceptron) comparison. \n",
    "##### **4.** Loss function comparison. \n",
    "##### **5.** Learning rates comparison. \n",
    "##### **6.** Optimizers comparison. \n",
    "##### **7.** Train best configuration for extra epochs on train+validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def researchBestModel(configureDS, datasets, epochsSearch, epochsBest, path, optimizers, \n",
    "                      learningRates, defaultHypers, losses, classifiers, defaultClassifier, \n",
    "                      defaultBackbone, backbonesForSearch, verbose=1, top=1):\n",
    "    trainDs, testDs, valDs = datasets\n",
    "    imgDim = configureDS.inputDim\n",
    "    nbClasses = len(configureDS.classNames)\n",
    "    outFilePath = path + 'ablationHistory.csv'\n",
    "    topModelsPath = path+'FinalModels/'\n",
    "    \n",
    "    print('Ablation for', configureDS.name)\n",
    "    \n",
    "    \n",
    "    baseStudy = {\n",
    "            \"architecture\": {\n",
    "                \"backbone\": defaultBackbone['backbone'](imgDim, weights=defaultBackbone['weights'], trainable=False),\n",
    "                \"classifier\": defaultClassifier(nbClasses, \"softmax\"),\n",
    "                \"inputLayer\": None, \n",
    "                \"inputDim\": imgDim\n",
    "            },\n",
    "            \"hyperparameters\": defaultHypers\n",
    "        }\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # ---- Stage 1 - Compare Transfer Learning Mode ----\n",
    "    # --------------------------------------------------\n",
    "    \n",
    "    trainingModeStudy = baseStudy\n",
    "    trainingModeStudy['architecture']['backbone'] = [\n",
    "                    defaultBackbone['backbone'](imgDim, weights=defaultBackbone['weights'], trainable=False, name='PT&Untrainable'),\n",
    "                    defaultBackbone['backbone'](imgDim, weights=defaultBackbone['weights'], trainable=True, name='PT&Trainable'),\n",
    "                    defaultBackbone['backbone'](imgDim, weights=None, trainable=True, name='IN&Trainable')\n",
    "                    ]    \n",
    "    trainingModeHistories = utils.researchStudies(trainDs, valDs, {'DNN-TransferLearningMode' : trainingModeStudy}, epochsSearch, verbose)\n",
    "    bestTrainMode = utils.getBestStudyFromHistories(trainingModeHistories)\n",
    "    trainable, pretrained = 'Trainable' in bestTrainMode, 'PT' in bestTrainMode\n",
    "    utils.displayStudiesProgress(trainingModeHistories, path, 'Comparison Transfer Learning Mode')\n",
    "    utils.saveStudyHistory({'DNN-TransferLearningMode' : trainingModeStudy}, trainingModeHistories, outFilePath)\n",
    "    print(\"Backbone Transfer Learning Mode Selected - Pretrained:\", pretrained, 'Trainable:', trainable)\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------\n",
    "    # ---- Stage 2 - Compare DNN Backbones -----\n",
    "    # ------------------------------------------\n",
    "    backboneConfigs = [backbone['backbone'](imgDim, weights=backbone['weights'], trainable=trainable) for backbone in backbonesForSearch]\n",
    "    bestBackboneStudy = copy.deepcopy(trainingModeHistories[bestTrainMode]['config'])\n",
    "    bestBackboneStudy[\"architecture\"][\"backbone\"] = backboneConfigs\n",
    "    bestBackboneHistories = utils.researchStudies(trainDs, valDs, {'Backbone': bestBackboneStudy}, epochsSearch, verbose)\n",
    "    bestBackboneHistories['Backbone'+\"_\"+defaultBackbone['backbone'].__name__] = trainingModeHistories[bestTrainMode]\n",
    "    bestBackbone = utils.getBestStudyFromHistories(bestBackboneHistories)\n",
    "    utils.displayStudiesProgress(bestBackboneHistories, path, 'Comparison DNN Backbone')\n",
    "    utils.saveStudyHistory({'BestBackbone': bestBackboneStudy}, bestBackboneHistories, outFilePath)\n",
    "    print(\"Best DNN Backbone:\", bestBackboneHistories[bestBackbone]['config'][\"architecture\"][\"backbone\"].name)\n",
    "\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # ---- Stage 3 - Compare FC Classifiers ----\n",
    "    # --------------------------------------------\n",
    "    classifierStudy = copy.deepcopy(bestBackboneHistories[bestBackbone]['config'])\n",
    "    classifierStudy['architecture'][\"classifier\"] = [classifier(nbClasses, \"softmax\") for classifier in classifiers]\n",
    "    classifierHistories = utils.researchStudies(trainDs, valDs, {'Classifiers': classifierStudy}, epochsSearch, verbose)\n",
    "    classifierHistories['Classifier'+\"_\"+str(defaultClassifier.__name__)] = bestBackboneHistories[bestBackbone]\n",
    "    bestClassifier = utils.getBestStudyFromHistories(classifierHistories)\n",
    "    utils.displayStudiesProgress(classifierHistories, path, 'Comparison Classifiers')\n",
    "    utils.saveStudyHistory({'bestClassifier': classifierStudy}, classifierHistories, outFilePath)\n",
    "    print(\"Best Classifier:\", str(classifierHistories[bestClassifier]['config']['architecture'][\"classifier\"]))\n",
    "    \n",
    "    # ------------------------------------------\n",
    "    # ---- Stage 4 - Compare Loss Functions ----\n",
    "    # ------------------------------------------\n",
    "    lossStudy = copy.deepcopy(classifierHistories[bestClassifier]['config'])\n",
    "    lossStudy['hyperparameters'][\"loss\"] = losses\n",
    "    lossesHistories = utils.researchStudies(trainDs, valDs, {'LossFunction': lossStudy}, epochsSearch, verbose)\n",
    "    lossesHistories['LossFunction'+\"_\"+str(defaultHypers[\"loss\"])] = classifierHistories[bestClassifier]\n",
    "    bestLoss = utils.getBestStudyFromHistories(lossesHistories)\n",
    "    utils.displayStudiesProgress(lossesHistories, path, 'Comparison Loss Functions')\n",
    "    utils.saveStudyHistory({'BestLoss': lossStudy}, lossesHistories, outFilePath)\n",
    "    print(\"Best Loss Function:\", str(lossesHistories[bestLoss]['config']['hyperparameters'][\"loss\"]))\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------\n",
    "    # ---- Stage 5 - Compare Learning Rates ----\n",
    "    # ------------------------------------------\n",
    "    learningRatesStudy = copy.deepcopy(lossesHistories[bestLoss]['config'])\n",
    "    learningRatesStudy['hyperparameters']['learningRate'] = learningRates\n",
    "    learningRatesHistories = utils.researchStudies(trainDs, valDs, {'LearningRate': learningRatesStudy}, epochsSearch, verbose)\n",
    "    learningRatesHistories['LearningRate'+\"_\"+str(defaultHypers[\"learningRate\"])] = lossesHistories[bestLoss]\n",
    "    bestLearningRate = utils.getBestStudyFromHistories(learningRatesHistories)\n",
    "    utils.displayStudiesProgress(learningRatesHistories, path, 'Comparison Learning Rate')\n",
    "    utils.saveStudyHistory({'BestLearningRate': learningRatesStudy}, learningRatesHistories, outFilePath)\n",
    "    print(\"Best Learning Rate:\", str(learningRatesHistories[bestLearningRate]['config'][\"hyperparameters\"][\"learningRate\"]))\n",
    "\n",
    "\n",
    "    # --------------------------------------\n",
    "    # ---- Stage 6 - Compare Optimizers ----\n",
    "    # --------------------------------------\n",
    "    optimizersStudy = copy.deepcopy(learningRatesHistories[bestLearningRate]['config'])\n",
    "    optimizersStudy[\"hyperparameters\"][\"optimizer\"] = optimizers\n",
    "    optimizersHistories = utils.researchStudies(trainDs, valDs, {'Optimizer' : optimizersStudy}, epochsSearch, verbose)\n",
    "    optimizersHistories['Optimizer'+\"_\"+defaultHypers['optimizer'].__name__] = learningRatesHistories[bestLearningRate]\n",
    "    bestOptimizier = utils.getBestStudyFromHistories(optimizersHistories)\n",
    "    utils.displayStudiesProgress(optimizersHistories, path, 'Comparison Optimizer')\n",
    "    utils.saveStudyHistory({'BestOptimizier': optimizersStudy}, optimizersHistories, outFilePath)\n",
    "    print(\"Best Optimizier:\", optimizersHistories[bestOptimizier]['config'][\"hyperparameters\"][\"optimizer\"].__name__)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ----------------------------------------------------------------\n",
    "    # ---- Stage 7 - Train top K Best models on train+validation -----\n",
    "    # ----------------------------------------------------------------\n",
    "    \n",
    "    histories = {\n",
    "        **trainingModeHistories, \n",
    "        **bestBackboneHistories, \n",
    "        **classifierHistories, \n",
    "        **lossesHistories,\n",
    "        **learningRatesHistories,\n",
    "        **optimizersHistories\n",
    "    }\n",
    "    \n",
    "    \n",
    "    Path(topModelsPath).mkdir(parents=True, exist_ok=True)\n",
    "    topKmodelsNames = utils.getBestStudyFromHistories(histories, top)\n",
    "    topModels = {x: histories.get(x, None) for x in topKmodelsNames}\n",
    "    topModelsTrainedHistories = {}\n",
    "    for modelName, model in topModels.items():\n",
    "        history = model['model'].fit(trainDs.concatenate(valDs), testDs, epochsBest, verbose=1)\n",
    "        model['model'].save(topModelsPath+modelName)\n",
    "        topModelsTrainedHistories[modelName] = {\n",
    "            \"history\":history,\n",
    "            \"model\": model['model'],\n",
    "            \"config\": model['config']\n",
    "        }\n",
    "    \n",
    "    utils.saveStudyHistory({'Best Models': None}, topModelsTrainedHistories, topModelsPath+'topHistories.csv', True)\n",
    "    utils.displayStudiesProgress(topModelsTrainedHistories, topModelsPath)\n",
    "    return topModelsTrainedHistories\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def researchStudy(study, path=None):\n",
    "    datasets = study['datasets']\n",
    "    studyParams = study['studyHyperParameters']\n",
    "    preparedDatasets = utils.prepareDatasetsForStudy(datasets, path)\n",
    "    bestModels = {}\n",
    "    for dsName, dsObj in preparedDatasets.items():\n",
    "        bestModels[dsName] = researchBestModel(**dsObj, **studyParams)\n",
    "    return bestModels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Datasets Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetsConfig = {\n",
    "    'batchSize': 32, \n",
    "    'parallelTune': tf.data.AUTOTUNE, \n",
    "    'split': [0.7, 0.15, 0.15], \n",
    "    'inputDim': (224, 224, 3), \n",
    "    'seed': 9, \n",
    "    'shuffle': True\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Gender** \n",
    "##### **Datasets:**\n",
    "* **SOCOFing**\n",
    "* **NIST Special Database 4**\n",
    "\n",
    "##### **Hyperparameters**\n",
    "* Optimizers: *Adam, Nadam, RMSprop*\n",
    "* Loss Functions: *binary-crossentropy, mean-squared-error, hinge*\n",
    "* Learning Rates: *0.1, 0.01, 0.001, 0.0001, 0.00001*\n",
    "* Backbones: *MobileNetV2, ResNet50, EfficientNetB2, InceptionV3, Xception*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "genderStudy = {\n",
    "    'datasets' : [\n",
    "        ds.SOCOFingGender(**datasetsConfig, ds.SOCOFingGender.UNDER_SAMPLING), \n",
    "        ds.NISTSDB4Fingers(**datasetsConfig), \n",
    "    ],\n",
    "    'studyHyperParameters' : {\n",
    "        'defaultBackbone': {'backbone' : bb.MobileNetV2, 'weights' : weightsMNV2},\n",
    "        'defaultClassifier': cf.DefaultClassifier,\n",
    "        'defaultHypers': {\n",
    "            \"optimizer\": Adam,\n",
    "            \"learningRate\": 0.001,\n",
    "            \"loss\": 'binary_crossentropy',\n",
    "            \"metrics\": 'accuracy'\n",
    "        },\n",
    "        'losses': ['mean_squared_error', 'hinge'],\n",
    "        'learningRates': [0.1, 0.01, 0.0001, 0.00001],\n",
    "        'optimizers': [Nadam, RMSprop],\n",
    "        'classifiers': [cf.AlexNetClassifier, cf.MobileNetClassifier, cf.ResNetClassifier],\n",
    "        'backbonesForSearch': [\n",
    "            {'backbone' : bb.ResNet50, 'weights' : weightsRN50},\n",
    "            {'backbone' : bb.EfficientNetB2, 'weights' : weightsENB2},\n",
    "            {'backbone' : bb.InceptionV3, 'weights' : weightsINCEPTIONV3},\n",
    "            {'backbone' : bb.Xception, 'weights' : weightsXCEPTION}, \n",
    "        ],\n",
    "        'epochsSearch': 10,\n",
    "        'epochsBest': 20,\n",
    "        'top': 5,\n",
    "        'verbose': 1\n",
    "    }\n",
    "}\n",
    "\n",
    "  \n",
    "genderBestModels = researchStudy(genderStudy, dbStudyOutPath.format('GenderStudy/{}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Finger Name** \n",
    "##### **Datasets:**\n",
    "* **SOCOFing**\n",
    "* **NIST Special Database 4**\n",
    "* **NIST Special Database 300a Roll**\n",
    "* **NIST Special Database 300b - All Scanners**\n",
    "\n",
    "##### **Hyperparameters**\n",
    "* Optimizers: *Adam, Nadam, RMSprop*\n",
    "* Loss Functions: *categorical-crossentropy, mean-squared-error, categorical-hinge*\n",
    "* Learning Rates: *0.1, 0.01, 0.001, 0.0001, 0.00001*\n",
    "* Backbones: *MobileNetV2, ResNet50, EfficientNetB2, InceptionV3, Xception*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: AMD Radeon Pro 5500M\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 1.99 GB\n",
      "\n",
      "Ablation for SOCOfingFingers\n",
      "Epoch 1/2\n",
      "132/132 [==============================] - 16s 101ms/step - loss: 2.5270 - accuracy: 0.1036 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/2\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 2.3050 - accuracy: 0.0964 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 1/2\n",
      "132/132 [==============================] - 42s 277ms/step - loss: 2.4679 - accuracy: 0.1510 - val_loss: 2.4752 - val_accuracy: 0.1000\n",
      "Epoch 2/2\n",
      "132/132 [==============================] - 35s 266ms/step - loss: 1.7720 - accuracy: 0.3329 - val_loss: 2.7066 - val_accuracy: 0.1000\n",
      "Epoch 1/2\n",
      "132/132 [==============================] - 42s 281ms/step - loss: 2.4991 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/2\n",
      "132/132 [==============================] - 37s 281ms/step - loss: 2.3064 - accuracy: 0.1021 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Backbone Transfer Learning Mode Selected - Pretrained: True Trainable: False\n",
      "{'history': <keras.callbacks.History object at 0x16bfcd250>, 'model': <FPMLmodule.fpml.FPML object at 0x16753ef70>, 'config': {'architecture': {'backbone': <FPMLmodule.backbones.mobilenet.MobileNet object at 0x167525100>, 'classifier': <FPMLmodule.classifiers.default.DefaultClassifier object at 0x167c9c640>, 'inputLayer': None, 'inputDim': (224, 224, 3)}, 'hyperparameters': {'optimizer': <class 'keras.optimizer_v2.adam.Adam'>, 'learningRate': 0.001, 'loss': 'categorical_crossentropy', 'metrics': 'accuracy'}}}\n",
      "Epoch 1/2\n",
      "161/161 [==============================] - 17s 108ms/step - loss: 2.3058 - accuracy: 0.0957 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/2\n",
      "161/161 [==============================] - 17s 108ms/step - loss: 2.3056 - accuracy: 0.0925 - val_loss: 2.3026 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_224_input with unsupported characters which will be renamed to mobilenetv2_1_00_224_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./out/FingerName/SOCOfingFingers/FinalModels/PT&Untrainable/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./out/FingerName/SOCOfingFingers/FinalModels/PT&Untrainable/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': <keras.callbacks.History object at 0x171be0a00>, 'model': <FPMLmodule.fpml.FPML object at 0x16aa6d430>, 'config': {'architecture': {'backbone': <FPMLmodule.backbones.mobilenet.MobileNet object at 0x167525be0>, 'classifier': <FPMLmodule.classifiers.default.DefaultClassifier object at 0x167c9cac0>, 'inputLayer': None, 'inputDim': (224, 224, 3)}, 'hyperparameters': {'optimizer': <class 'keras.optimizer_v2.adam.Adam'>, 'learningRate': 0.001, 'loss': 'categorical_crossentropy', 'metrics': 'accuracy'}}}\n",
      "Epoch 1/2\n",
      "161/161 [==============================] - 44s 269ms/step - loss: 1.4871 - accuracy: 0.4335 - val_loss: 2.4682 - val_accuracy: 0.1000\n",
      "Epoch 2/2\n",
      "161/161 [==============================] - 48s 300ms/step - loss: 1.3639 - accuracy: 0.5061 - val_loss: 2.3164 - val_accuracy: 0.1411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_224_input with unsupported characters which will be renamed to mobilenetv2_1_00_224_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./out/FingerName/SOCOfingFingers/FinalModels/PT&Trainable/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./out/FingerName/SOCOfingFingers/FinalModels/PT&Trainable/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PT&Untrainable': {'history': <keras.callbacks.History object at 0x191da0d00>, 'model': <FPMLmodule.fpml.FPML object at 0x16753ef70>, 'config': {'architecture': {'backbone': <FPMLmodule.backbones.mobilenet.MobileNet object at 0x167525100>, 'classifier': <FPMLmodule.classifiers.default.DefaultClassifier object at 0x167c9c640>, 'inputLayer': None, 'inputDim': (224, 224, 3)}, 'hyperparameters': {'optimizer': <class 'keras.optimizer_v2.adam.Adam'>, 'learningRate': 0.001, 'loss': 'categorical_crossentropy', 'metrics': 'accuracy'}}}, 'PT&Trainable': {'history': <keras.callbacks.History object at 0x1745d69d0>, 'model': <FPMLmodule.fpml.FPML object at 0x16aa6d430>, 'config': {'architecture': {'backbone': <FPMLmodule.backbones.mobilenet.MobileNet object at 0x167525be0>, 'classifier': <FPMLmodule.classifiers.default.DefaultClassifier object at 0x167c9cac0>, 'inputLayer': None, 'inputDim': (224, 224, 3)}, 'hyperparameters': {'optimizer': <class 'keras.optimizer_v2.adam.Adam'>, 'learningRate': 0.001, 'loss': 'categorical_crossentropy', 'metrics': 'accuracy'}}}}\n",
      "Ablation for NISTSDB4Fingers\n",
      "Epoch 1/2\n",
      "88/88 [==============================] - 13s 113ms/step - loss: 2.5571 - accuracy: 0.0986 - val_loss: 2.3025 - val_accuracy: 0.1067\n",
      "Epoch 2/2\n",
      "88/88 [==============================] - 8s 89ms/step - loss: 2.3058 - accuracy: 0.0996 - val_loss: 2.3021 - val_accuracy: 0.1067\n",
      "Epoch 1/2\n",
      "88/88 [==============================] - 33s 309ms/step - loss: 2.6816 - accuracy: 0.1321 - val_loss: 2.3065 - val_accuracy: 0.1233\n",
      "Epoch 2/2\n",
      "88/88 [==============================] - 27s 310ms/step - loss: 2.1620 - accuracy: 0.1864 - val_loss: 2.3098 - val_accuracy: 0.0700\n",
      "Epoch 1/2\n",
      "88/88 [==============================] - 37s 318ms/step - loss: 2.5589 - accuracy: 0.1057 - val_loss: 2.3028 - val_accuracy: 0.1067\n",
      "Epoch 2/2\n",
      "88/88 [==============================] - 33s 379ms/step - loss: 2.3163 - accuracy: 0.1089 - val_loss: 2.3026 - val_accuracy: 0.1067\n",
      "Backbone Transfer Learning Mode Selected - Pretrained: True Trainable: False\n",
      "{'history': <keras.callbacks.History object at 0x1753fae80>, 'model': <FPMLmodule.fpml.FPML object at 0x1800531c0>, 'config': {'architecture': {'backbone': <FPMLmodule.backbones.mobilenet.MobileNet object at 0x18df4fd90>, 'classifier': <FPMLmodule.classifiers.default.DefaultClassifier object at 0x180063b20>, 'inputLayer': None, 'inputDim': (224, 224, 3)}, 'hyperparameters': {'optimizer': <class 'keras.optimizer_v2.adam.Adam'>, 'learningRate': 0.001, 'loss': 'categorical_crossentropy', 'metrics': 'accuracy'}}}\n",
      "Epoch 1/2\n",
      "107/107 [==============================] - 10s 94ms/step - loss: 2.3048 - accuracy: 0.0997 - val_loss: 2.3008 - val_accuracy: 0.1217\n",
      "Epoch 2/2\n",
      "107/107 [==============================] - 10s 94ms/step - loss: 2.3021 - accuracy: 0.1050 - val_loss: 2.3003 - val_accuracy: 0.1117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_224_input with unsupported characters which will be renamed to mobilenetv2_1_00_224_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./out/FingerName/NISTSDB4Fingers/FinalModels/PT&Untrainable/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./out/FingerName/NISTSDB4Fingers/FinalModels/PT&Untrainable/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': <keras.callbacks.History object at 0x1748d8df0>, 'model': <FPMLmodule.fpml.FPML object at 0x18fb69310>, 'config': {'architecture': {'backbone': <FPMLmodule.backbones.mobilenet.MobileNet object at 0x174e7b7f0>, 'classifier': <FPMLmodule.classifiers.default.DefaultClassifier object at 0x17f764ee0>, 'inputLayer': None, 'inputDim': (224, 224, 3)}, 'hyperparameters': {'optimizer': <class 'keras.optimizer_v2.adam.Adam'>, 'learningRate': 0.001, 'loss': 'categorical_crossentropy', 'metrics': 'accuracy'}}}\n",
      "Epoch 1/2\n",
      "107/107 [==============================] - 35s 326ms/step - loss: 2.3060 - accuracy: 0.1085 - val_loss: 2.3010 - val_accuracy: 0.1217\n",
      "Epoch 2/2\n",
      "107/107 [==============================] - 30s 283ms/step - loss: 2.3029 - accuracy: 0.1082 - val_loss: 2.3003 - val_accuracy: 0.1217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_224_input with unsupported characters which will be renamed to mobilenetv2_1_00_224_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./out/FingerName/NISTSDB4Fingers/FinalModels/IN&Trainable/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./out/FingerName/NISTSDB4Fingers/FinalModels/IN&Trainable/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PT&Untrainable': {'history': <keras.callbacks.History object at 0x1baac1fa0>, 'model': <FPMLmodule.fpml.FPML object at 0x1800531c0>, 'config': {'architecture': {'backbone': <FPMLmodule.backbones.mobilenet.MobileNet object at 0x18df4fd90>, 'classifier': <FPMLmodule.classifiers.default.DefaultClassifier object at 0x180063b20>, 'inputLayer': None, 'inputDim': (224, 224, 3)}, 'hyperparameters': {'optimizer': <class 'keras.optimizer_v2.adam.Adam'>, 'learningRate': 0.001, 'loss': 'categorical_crossentropy', 'metrics': 'accuracy'}}}, 'IN&Trainable': {'history': <keras.callbacks.History object at 0x1bb461640>, 'model': <FPMLmodule.fpml.FPML object at 0x18fb69310>, 'config': {'architecture': {'backbone': <FPMLmodule.backbones.mobilenet.MobileNet object at 0x174e7b7f0>, 'classifier': <FPMLmodule.classifiers.default.DefaultClassifier object at 0x17f764ee0>, 'inputLayer': None, 'inputDim': (224, 224, 3)}, 'hyperparameters': {'optimizer': <class 'keras.optimizer_v2.adam.Adam'>, 'learningRate': 0.001, 'loss': 'categorical_crossentropy', 'metrics': 'accuracy'}}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fingerNameStudy = {\n",
    "    'datasets' : [\n",
    "        ds.SOCOFingFingers(**datasetsConfig), \n",
    "        ds.NISTSDB4Fingers(**datasetsConfig), \n",
    "        ds.NISTSDB300aFingers(**datasetsConfig), \n",
    "        ds.NISTSDB302bFingers(**datasetsConfig)\n",
    "    ][:2],\n",
    "    'studyHyperParameters' : {\n",
    "        'defaultBackbone': {'backbone' : bb.MobileNetV2, 'weights' : weightsMNV2},\n",
    "        'defaultClassifier': cf.DefaultClassifier,\n",
    "        'defaultHypers': {\n",
    "            \"optimizer\": Adam,\n",
    "            \"learningRate\": 0.001,\n",
    "            \"loss\": 'categorical_crossentropy',\n",
    "            \"metrics\": 'accuracy'\n",
    "        },\n",
    "        'losses': ['mean_squared_error', 'categorical_hinge'][:1],\n",
    "        'learningRates': [0.1, 0.01, 0.0001, 0.00001][:1],\n",
    "        'optimizers': [Nadam, RMSprop][:1],\n",
    "        'classifiers': [cf.AlexNetClassifier, cf.MobileNetClassifier, cf.ResNetClassifier][:1],\n",
    "        'backbonesForSearch': [\n",
    "            {'backbone' : bb.ResNet50, 'weights' : weightsRN50},\n",
    "            {'backbone' : bb.EfficientNetB2, 'weights' : weightsENB2},\n",
    "            {'backbone' : bb.InceptionV3, 'weights' : weightsINCEPTIONV3},\n",
    "            {'backbone' : bb.Xception, 'weights' : weightsXCEPTION}, \n",
    "        ][:1],\n",
    "        'epochsSearch': 2,\n",
    "        'epochsBest': 2,\n",
    "        'top': 2,\n",
    "        'verbose': 1\n",
    "    }\n",
    "}\n",
    "\n",
    "  \n",
    "fingersBestModels = researchStudy(fingerNameStudy, dbStudyOutPath.format('FingerName/{}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOCOfingFingers <FPMLmodule.fpml.FPML object at 0x16753ef70>\n",
      "SOCOfingFingers <FPMLmodule.fpml.FPML object at 0x16aa6d430>\n",
      "NISTSDB4Fingers <FPMLmodule.fpml.FPML object at 0x1800531c0>\n",
      "NISTSDB4Fingers <FPMLmodule.fpml.FPML object at 0x18fb69310>\n"
     ]
    }
   ],
   "source": [
    "for x, y in fingersBestModels.items():\n",
    "    for z, w in y.items():\n",
    "        print(x, w['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Fingerprint type** \n",
    "##### **Datasets:**\n",
    "* **NIST Special Database 4**\n",
    "\n",
    "##### **Hyperparameters**\n",
    "* Optimizers: *Adam, Nadam, RMSprop*\n",
    "* Loss Functions: *categorical-crossentropy, mean-squared-error, categorical-hinge*\n",
    "* Learning Rates: *0.1, 0.01, 0.001, 0.0001, 0.00001*\n",
    "* Backbones: *MobileNetV2, ResNet50, EfficientNetB2, InceptionV3, Xception*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fingerprintTypeNameStudy = {\n",
    "    'datasets' : [\n",
    "        ds.NISTSDB4Type(**datasetsConfig), \n",
    "    ],\n",
    "    'studyHyperParameters' : {\n",
    "        'defaultBackbone': {'backbone' : bb.MobileNetV2, 'weights' : weightsMNV2},\n",
    "        'defaultClassifier': cf.DefaultClassifier,\n",
    "        'defaultHypers': {\n",
    "            \"optimizer\": Adam,\n",
    "            \"learningRate\": 0.001,\n",
    "            \"loss\": 'categorical_crossentropy',\n",
    "            \"metrics\": 'accuracy'\n",
    "        },\n",
    "        'losses': ['mean_squared_error', 'categorical_hinge'],\n",
    "        'learningRates': [0.1, 0.01, 0.0001, 0.00001],\n",
    "        'optimizers': [Nadam, RMSprop],\n",
    "        'classifiers': [cf.AlexNetClassifier, cf.MobileNetClassifier, cf.ResNetClassifier],\n",
    "        'backbonesForSearch': [\n",
    "            {'backbone' : bb.ResNet50, 'weights' : weightsRN50},\n",
    "            {'backbone' : bb.EfficientNetB2, 'weights' : weightsENB2},\n",
    "            {'backbone' : bb.InceptionV3, 'weights' : weightsINCEPTIONV3},\n",
    "            {'backbone' : bb.Xception, 'weights' : weightsXCEPTION}, \n",
    "        ],\n",
    "        'epochsSearch': 10,\n",
    "        'epochsBest': 20,\n",
    "        'top': 5,\n",
    "        'verbose': 1\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "  \n",
    "fingerprintTypeBestModels = researchStudy(fingerprintTypeNameStudy, dbStudyOutPath.format('FingerprintType/{}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Same Person** \n",
    "##### **Datasets:**\n",
    "* **NIST Special Database 4**\n",
    "\n",
    "##### **Hyperparameters**\n",
    "* Optimizers: *Adam, Nadam, RMSprop*\n",
    "* Loss Functions: *binary-crossentropy, mean-squared-error, hinge*\n",
    "* Learning Rates: *0.1, 0.01, 0.001, 0.0001, 0.00001*\n",
    "* Backbones: *MobileNetV2, ResNet50, EfficientNetB2, InceptionV3, Xception*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samePersonStudy = {\n",
    "    'datasets' : [\n",
    "        ds.SOCOFingSamePerson(**datasetsConfig), \n",
    "        ds.NISTSDB300aSamePerson(**datasetsConfig), \n",
    "        ds.NISTSDB302bSamePerson(**datasetsConfig), \n",
    "    ],\n",
    "    'studyHyperParameters' : {\n",
    "        'defaultBackbone': {'backbone' : bb.MobileNetV2, 'weights' : weightsMNV2},\n",
    "        'defaultClassifier': cf.DefaultClassifier,\n",
    "        'defaultHypers': {\n",
    "            \"optimizer\": Adam,\n",
    "            \"learningRate\": 0.001,\n",
    "            \"loss\": 'binary_crossentropy',\n",
    "            \"metrics\": 'accuracy'\n",
    "        },\n",
    "        'losses': ['mean_squared_error', 'hinge'],\n",
    "        'learningRates': [0.1, 0.01, 0.0001, 0.00001],\n",
    "        'optimizers': [Nadam, RMSprop],\n",
    "        'classifiers': [cf.AlexNetClassifier, cf.MobileNetClassifier, cf.ResNetClassifier],\n",
    "        'backbonesForSearch': [\n",
    "            {'backbone' : bb.ResNet50, 'weights' : weightsRN50},\n",
    "            {'backbone' : bb.EfficientNetB2, 'weights' : weightsENB2},\n",
    "            {'backbone' : bb.InceptionV3, 'weights' : weightsINCEPTIONV3},\n",
    "            {'backbone' : bb.Xception, 'weights' : weightsXCEPTION}, \n",
    "        ],\n",
    "        'epochsSearch': 10,\n",
    "        'epochsBest': 20,\n",
    "        'top': 5,\n",
    "        'verbose': 1\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "  \n",
    "samePersonBestModels = researchStudy(samePersonStudy, dbStudyOutPath.format('SamePerson/{}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingersBestModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluteStudyOnOthersDatasets(bestModels, datasets, epochsFinal, verbose=1, path=None):\n",
    "    \n",
    "    evaluations = {}\n",
    "    for datasetName, bestDatasetModels in bestModels.items():\n",
    "        chainedTrain = None\n",
    "        chainedTest = None\n",
    "        for dset in datasets:\n",
    "            dset.split = [1]\n",
    "            [toConcat] = dset.create()\n",
    "            if(dset.name != datasetName):\n",
    "                if chainedTrain == None:\n",
    "                    chainedTrain = toConcat\n",
    "                else:\n",
    "                    chainedTrain = chainedTrain.concatenate(toConcat)\n",
    "            else:\n",
    "                if chainedTest == None:\n",
    "                    chainedTest = toConcat\n",
    "                else:\n",
    "                    chainedTest.concatenate(toConcat)\n",
    "        evaluations[datasetName] = {}\n",
    "        for modelName, model in bestDatasetModels.items():\n",
    "            evaluation = model['model'].getModel().evaluate(chainedTrain)\n",
    "            evaluations[datasetName][modelName] = {\n",
    "                'evaluation': evaluation,\n",
    "                'train' : chainedTrain, \n",
    "                'test': chainedTest\n",
    "            }\n",
    "    return evaluations    \n",
    "\n",
    "    # finalModelConfiguration = bestModels[bestModelName][1]\n",
    "    # finalModel = FPML(**finalModelConfiguration[\"architecture\"]).create(**finalModelConfiguration[\"hyperparameters\"])\n",
    "    # finalModelHistory = finalModel.fit(finalDs['train'], validation_data=finalDs['test'], epochs=epochsFinal, verbose=verbose)\n",
    "    \n",
    "    # utils.datasetAnalysisAndDisplay([finalDs['train'], finalDs['test']], datasets[0], path)\n",
    "    \n",
    "    # toSave = {'Final Model':{'history' : finalModelHistory, 'config' : finalModelConfiguration}}\n",
    "    \n",
    "    # finalModel.save(path+'FinalModel-'+bestModelName)\n",
    "    # utils.displayStudiesProgress(toSave, path, 'Final Model')\n",
    "    # utils.saveStudyHistory({'Final Model': finalModelConfiguration}, toSave, path+'finalModel.csv')\n",
    "    # utils.displayConfusion(finalDs['test'], finalModel, path)\n",
    "\n",
    "\n",
    "evaluations = evaluteStudyOnOthersDatasets(fingersBestModels, fingerNameStudy['datasets'], 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in fingersBestModels.items():\n",
    "    for key2, val2 in val.items():\n",
    "        print(val2['model'].getModel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfmetal",
   "language": "python",
   "name": "tfmetal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
