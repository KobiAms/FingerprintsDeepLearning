{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import datasets as ds\n",
    "import FPMLmodule.utils as utils\n",
    "import tensorflow as tf\n",
    "import FPMLmodule.backbones as backbones\n",
    "import FPMLmodule.classifiers as classifiers\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop\n",
    "from FPMLmodule.fpml import FPML \n",
    "from pathlib import Path\n",
    "\n",
    "print('TensorFlow Version:', tf.__version__)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsRN50 = \"./weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "weightsMNV2 = \"./weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\"\n",
    "weightsENB2 = \"./weights/efficientnetb2_notop.h5\"\n",
    "weightsINCEPTIONV3 = \"./weights/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "weightsXCEPTION = \"./weights/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablation(configureDS, datasets, imgDim,epochsSearch, epochsBest, path, optimizers, learningRates, hypers, losses, backboneForTypeMode, verbose=1):\n",
    "    trainDs, testDs, valDs = datasets\n",
    "    nbClasses = len(configureDS.classNames)\n",
    "    activation = \"softmax\"\n",
    "    outFilePath = path + 'ablationHistory.csv'\n",
    "    \n",
    "    trainingModeStudy =  {\n",
    "        'DNN-TransferLearningMode' : {\n",
    "            \"architecture\": {\n",
    "                \"backbone\": [\n",
    "                    backboneForTypeMode(imgDim, weights=weightsMNV2, trainable=False, name=backboneForTypeMode.__name__+'PT&Untrainable')#,\n",
    "                    # backboneForTypeMode(imgDim, weights=weightsMNV2, trainable=True, name=backboneForTypeMode.__name__+'PT&Trainable'),\n",
    "                    # backboneForTypeMode(imgDim, weights=None, trainable=True, name=backboneForTypeMode.__name__+'IN&Trainable')\n",
    "                    ],\n",
    "                \"classfier\": classifiers.DefaultClassifier(nbClasses, activation),\n",
    "                \"inputLayer\": None, \n",
    "                \"inputDim\": imgDim\n",
    "            },\n",
    "            \"hyperparameters\":hypers\n",
    "        }\n",
    "    }\n",
    "    trainingModeHistories = utils.researchStudies(trainDs, valDs, trainingModeStudy, epochsSearch, verbose)\n",
    "    trainingModeBestModel = utils.getBestStudyFromHistories(trainingModeHistories)\n",
    "    trainable = 'Trainable' in trainingModeBestModel\n",
    "    pretrained = 'PT' in trainingModeBestModel\n",
    "    utils.saveStudyHistory(trainingModeStudy, trainingModeHistories, outFilePath)\n",
    "\n",
    "    print(\"Training Mode Selected - Pretrained:\", pretrained, 'Trainable:', trainable)\n",
    "\n",
    "    # Backbone\n",
    "    bestBackboneStudy = {\n",
    "        \"bestBackbone\" : {\n",
    "            \"architecture\": {\n",
    "                \"backbone\": [\n",
    "                    backbones.ResNet50(imgDim, weights=weightsRN50, trainable=trainable)#,\n",
    "                    # backbones.EfficientNetB2(imgDim, weights=weightsENB2, trainable=trainable),\n",
    "                    # backbones.InceptionV3(imgDim, weights=weightsINCEPTIONV3, trainable=trainable),\n",
    "                    # backbones.Xception(imgDim, weights=weightsXCEPTION, trainable=trainable)\n",
    "                    ],\n",
    "                \"classfier\": classifiers.DefaultClassifier(nbClasses, activation),\n",
    "                \"inputLayer\":\"\", \n",
    "                \"inputDim\": imgDim\n",
    "            },\n",
    "            \"hyperparameters\": hypers\n",
    "        },\n",
    "    }\n",
    "    bestBackboneHistories = utils.researchStudies(trainDs, valDs, bestBackboneStudy, epochsSearch, verbose)\n",
    "    bestBackboneHistories[trainingModeBestModel] = trainingModeHistories[trainingModeBestModel]\n",
    "    bestBackbone = utils.getBestStudyFromHistories(bestBackboneHistories)\n",
    "    utils.saveStudyHistory(bestBackboneStudy, bestBackboneHistories, outFilePath)\n",
    "    print(\"Best DNN Backbon:\", bestBackbone)\n",
    "\n",
    "\n",
    "    # Optimizer\n",
    "    optimizersStudy = copy.deepcopy(bestBackboneHistories[bestBackbone]['config'])\n",
    "    optimizersStudy[\"hyperparameters\"][\"optimizer\"] = optimizers[:1]\n",
    "    optimizersHistories = utils.researchStudies(trainDs, valDs, {bestBackbone : optimizersStudy}, epochsSearch, verbose)\n",
    "    optimizersHistories[bestBackbone+\"_Adam\"] = bestBackboneHistories[bestBackbone]\n",
    "    bestOptimizier = utils.getBestStudyFromHistories(optimizersHistories)\n",
    "    utils.saveStudyHistory({bestBackbone: optimizersStudy}, optimizersHistories, outFilePath)\n",
    "    print(\"Best Optimizier:\", bestOptimizier)\n",
    "\n",
    "\n",
    "    # Learning rate\n",
    "    learningRatesStudy = copy.deepcopy(optimizersHistories[bestOptimizier]['config'])\n",
    "    learningRatesStudy['hyperparameters']['learningRate'] = learningRates[:1]\n",
    "    learningRatesHistories = utils.researchStudies(trainDs, valDs, {bestOptimizier: learningRatesStudy}, epochsSearch, verbose)\n",
    "    learningRatesHistories[bestOptimizier+\"_\"+str(hypers[\"learningRate\"])] = optimizersHistories[bestOptimizier]\n",
    "    bestLearningRate = utils.getBestStudyFromHistories(learningRatesHistories)\n",
    "    utils.saveStudyHistory({bestOptimizier: learningRatesStudy}, learningRatesHistories, outFilePath)\n",
    "    print(\"Best Learning Rate:\", bestLearningRate)\n",
    "    \n",
    "    # loss function\n",
    "    lossStudy = copy.deepcopy(learningRatesHistories[bestLearningRate]['config'])\n",
    "    lossStudy['hyperparameters'][\"loss\"] = losses[:1]\n",
    "    lossesHistories = utils.researchStudies(trainDs, valDs, {bestLearningRate: lossStudy}, epochsSearch, verbose)\n",
    "    lossesHistories[bestLearningRate+\"_\"+str(hypers[\"loss\"])] = learningRatesHistories[bestLearningRate]\n",
    "    bestLoss = utils.getBestStudyFromHistories(lossesHistories)\n",
    "    utils.saveStudyHistory({bestLearningRate: lossStudy}, lossesHistories, outFilePath)\n",
    "    print(bestLoss)\n",
    "\n",
    "    bestModelName = bestLoss\n",
    "    bestModelConfiguration = lossesHistories[bestLoss]['config']\n",
    "    trainValDs = trainDs.concatenate(valDs)\n",
    "    \n",
    "    bestModel = FPML(**bestModelConfiguration[\"architecture\"]).create(**bestModelConfiguration[\"hyperparameters\"])\n",
    "    bestModelHistory = bestModel.fit(trainValDs, validation_data=testDs, epochs=epochsBest, verbose=verbose)\n",
    "    toSave = {'Best Model':{'history' : bestModelHistory, 'config' : bestModelConfiguration}}\n",
    "    utils.saveStudyHistory({'Best Model': bestModelConfiguration}, toSave, outFilePath)\n",
    "    bestModel.save('./weights/FPML_'+configureDS.name+'_'+bestModelName+\".h5\")\n",
    "    \n",
    "\n",
    "optimizers=[Nadam, RMSprop]\n",
    "learningRates = [0.1, 0.01, 0.0001, 0.00001]\n",
    "defaultHypers = {\n",
    "        \"optimizer\": Adam,\n",
    "        \"learningRate\": 0.001,\n",
    "        \"loss\": 'binary_crossentropy',\n",
    "        \"metrics\": 'accuracy'\n",
    "    }\n",
    "losses = ['binary_focal_crossentropy', 'hinge']\n",
    "backboneForTypeMode = backbones.MobileNetV2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Config\n",
    "seed=9\n",
    "imgDim = (120, 120, 3)\n",
    "imgHeight, imgWidth, imgChannels = imgDim\n",
    "batchSize = 32\n",
    "verbose = 1\n",
    "outDir = './finalout/'\n",
    "\n",
    "# Dataset configuration\n",
    "dsConfig = {\n",
    "    'batchSize': batchSize, \n",
    "    'parallelTune': tf.data.AUTOTUNE, \n",
    "    'split': [0.7, 0.15, 0.15], \n",
    "    'inputDim': (120, 120, 3), \n",
    "    'seed': seed, \n",
    "    'shuffle': True\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Training interval\n",
    "epochsForSearch = 1\n",
    "epochsForBest = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Dataset = ds.SOCOFingGender\n",
    "configureDS = Dataset(**dsConfig, sampling=ds.SOCOFingGender.UNDER_SAMPLING)\n",
    "datasets = configureDS.create()\n",
    "dbStudyOutPath = outDir+'/'+configureDS.name+'/'\n",
    "Path(dbStudyOutPath).mkdir(parents=True, exist_ok=True)\n",
    "utils.datasetAnalysisAndDisplay(datasets, configureDS, dbStudyOutPath)\n",
    "ablation(configureDS, datasets, imgDim, epochsForSearch, epochsForBest, dbStudyOutPath+'/', optimizers, learningRates, defaultHypers, losses, backboneForTypeMode, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Dataset = ds.SOCOFingHeands\n",
    "configureDS = Dataset(**dsConfig)\n",
    "datasets = configureDS.create()\n",
    "dbStudyOutPath = outDir+'/'+configureDS.name+'/'\n",
    "Path(dbStudyOutPath).mkdir(parents=True, exist_ok=True)\n",
    "utils.datasetAnalysisAndDisplay(datasets, configureDS, dbStudyOutPath)\n",
    "ablation(configureDS, datasets, imgDim, epochsForSearch, epochsForBest, dbStudyOutPath+'/', optimizers, learningRates, defaultHypers, losses, backboneForTypeMode, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfmetal",
   "language": "python",
   "name": "tfmetal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
