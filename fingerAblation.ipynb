{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Fingerprints Finger Classification**\n",
    "## JCE - Final Project \n",
    "### By Kobi Amsellem & Zohar Kedem\n",
    "\n",
    "#### Find a model that helps a forensic investigator decide To which finger does the fingerprint belong\n",
    "#### 10 classeses Classification (thumnb, index, middle, ring, little)*(right, left)\n",
    "\n",
    "Expirements:\n",
    "1. decide of using transfer learning or full training \n",
    "2. Comparison between couple of backbones models \n",
    "3. Comparison optimizers\n",
    "4. Comparison learning rates\n",
    "5. Comparison loss function\n",
    "\n",
    "* train best model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import SOCOFingFingers\n",
    "import FPMLmodule.backbones as backbones\n",
    "import FPMLmodule.classifiers as classifiers\n",
    "import FPMLmodule.utils as utils\n",
    "from FPMLmodule.fpml import FPML \n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hyperparameters and default settings**  ###\n",
    "\n",
    "* define the global configuration for training\n",
    "* define datset configuration as split, batch size etc.\n",
    "* declare relevant backbones weights path\n",
    "* set epochs for study and final model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Config\n",
    "seed=9\n",
    "imgDim = (120, 120, 3)\n",
    "imgHeight, imgWidth, imgChannels = imgDim\n",
    "batchSize = 32\n",
    "\n",
    "# Dataset configuration\n",
    "dsConfig = {\n",
    "    'batchSize': batchSize, \n",
    "    'parallelTune': tf.data.AUTOTUNE, \n",
    "    'split': [0.7, 0.15, 0.15], \n",
    "    'inputDim': imgDim, \n",
    "    'seed': seed, \n",
    "    'shuffle': True\n",
    "    }\n",
    "\n",
    "weightsRN50 = \"./weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "weightsMNV2 = \"./weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\"\n",
    "weightsENB2 = \"./weights/efficientnetb2_notop.h5\"\n",
    "weightsINCEPTIONV3 = \"./weights/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "weightsXCEPTION = \"./weights/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Training interval\n",
    "epochsForSearch = 10\n",
    "epochsForBest = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create Dataset**\n",
    "\n",
    "* labeld as Male/Female \n",
    "* sampling mode\n",
    "* split to train/test/validation sub-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOCOFingers = SOCOFingFingers(**dsConfig)\n",
    "fingersDs = SOCOFingers.create()\n",
    "trainDs, testDs, valDs = fingersDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Datasets Split Sizes and split diversity ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.displayDatasetSplitInformation(fingersDs, SOCOFingers.classNames)\n",
    "utils.displayDsSamples(trainDs, shape=(5,5), classNames=SOCOFingers.classNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define base hyperparameters for study ###\n",
    "* optimizer\n",
    "* learning rate\n",
    "* loss function\n",
    "* accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbClasses = len(SOCOFingers.classNames)\n",
    "activation = \"softmax\"\n",
    "hypers = {\n",
    "    \"optimizer\": Adam,\n",
    "    \"learningRate\": 0.001,\n",
    "    \"loss\": 'binary_crossentropy',\n",
    "    \"metrics\": 'accuracy'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using MobileNetV2 to compare transfer learning options**\n",
    "\n",
    "define 3 studies using mobilenet as backbone to compare between:\n",
    "* transfer learning from imagenet and train the classifier only\n",
    "* transfer learning from imagenet and train the whole model\n",
    "* train the model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainingModeStudy = {\n",
    "    \"mobilenetV2-pretrained-untrainable\" : {\n",
    "        \"architecture\": {\n",
    "            \"backbone\": backbones.MobileNetV2(imgDim, weights=weightsMNV2, trainable=False),\n",
    "            \"classfier\": classifiers.DefaultClassifier(nbClasses, activation),\n",
    "            \"inputLayer\": None, \n",
    "            \"inputDim\": imgDim\n",
    "        },\n",
    "        \"hyperparameters\":hypers\n",
    "    },\n",
    "    \"MobileNetV2-pretrained-trainable\" : {\n",
    "        \"architecture\": {\n",
    "            \"backbone\": backbones.MobileNetV2(imgDim, weights=weightsMNV2, trainable=True),\n",
    "            \"classfier\": classifiers.DefaultClassifier(nbClasses, activation),\n",
    "            \"inputLayer\": None, \n",
    "            \"inputDim\": imgDim\n",
    "        },\n",
    "        \"hyperparameters\":hypers\n",
    "    },\n",
    "    \"MobileNetV2-fulltraining\" : {\n",
    "        \"architecture\": {\n",
    "            \"backbone\": backbones.MobileNetV2(imgDim, weights=None, trainable=True),\n",
    "            \"classfier\": classifiers.DefaultClassifier(nbClasses, activation),\n",
    "            \"inputLayer\": None, \n",
    "            \"inputDim\": imgDim\n",
    "        },\n",
    "        \"hyperparameters\":hypers\n",
    "    }\n",
    "}\n",
    "\n",
    "trainingModeHistories = utils.researchStudies(trainDs, valDs, trainingModeStudy, epochsForSearch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### examine transfer learing mode results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.displayStudiesProgress(trainingModeHistories)\n",
    "trainingModeBestModel = utils.getBestStudyFromHistories(trainingModeHistories)\n",
    "pretrained = 'pretrained' in trainingModeBestModel\n",
    "trainable = 'untrainable' not in trainingModeBestModel\n",
    "print(trainingModeBestModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparing Backbones**\n",
    "\n",
    "define studies using different backbone to compare between:\n",
    "* ResNet50\n",
    "* EfficientNetB2\n",
    "* InceptionV3\n",
    "* Xception\n",
    "* MobileNetV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestBackboneStudy = {\n",
    "    \"resnet50\" : {\n",
    "        \"architecture\": {\n",
    "            \"backbone\": backbones.ResNet50(imgDim, weights=weightsRN50, trainable=trainable),\n",
    "            \"classfier\": classifiers.DefaultClassifier(nbClasses, activation),\n",
    "            \"inputLayer\":\"\", \n",
    "            \"inputDim\": imgDim\n",
    "        },\n",
    "        \"hyperparameters\": hypers\n",
    "    },\n",
    "    \"efficientnet\" : {\n",
    "        \"architecture\": {\n",
    "            \"backbone\": backbones.EfficientNetB2(imgDim, weights=weightsENB2, trainable=trainable),\n",
    "            \"classfier\": classifiers.DefaultClassifier(nbClasses, activation),\n",
    "            \"inputLayer\":\"\", \n",
    "            \"inputDim\": imgDim\n",
    "        },\n",
    "        \"hyperparameters\": hypers\n",
    "    },\n",
    "    \"inceptionV3\" : {\n",
    "        \"architecture\": {\n",
    "            \"backbone\": backbones.InceptionV3(imgDim, weights=weightsINCEPTIONV3, trainable=trainable),\n",
    "            \"classfier\": classifiers.DefaultClassifier(nbClasses, activation),\n",
    "            \"inputLayer\":\"\", \n",
    "            \"inputDim\": imgDim\n",
    "        },\n",
    "        \"hyperparameters\": hypers\n",
    "    },\n",
    "    \"xception\" : {\n",
    "        \"architecture\": {\n",
    "            \"backbone\": backbones.Xception(imgDim, weights=weightsXCEPTION, trainable=trainable),\n",
    "            \"classfier\": classifiers.DefaultClassifier(nbClasses, activation),\n",
    "            \"inputLayer\":\"\", \n",
    "            \"inputDim\": imgDim\n",
    "        },\n",
    "        \"hyperparameters\": hypers\n",
    "    },\n",
    "    \n",
    "}\n",
    "\n",
    "bestBackboneHistories = utils.researchStudies(trainDs, valDs, bestBackboneStudy, epochsForSearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### examine backbone study results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestBackboneHistories[trainingModeBestModel] = trainingModeHistories[trainingModeBestModel]\n",
    "bestBackboneStudy[trainingModeBestModel] = trainingModeStudy[trainingModeBestModel]\n",
    "utils.displayStudiesProgress(bestBackboneHistories)\n",
    "bestBackbone = utils.getBestStudyFromHistories(bestBackboneHistories)\n",
    "print(bestBackbone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparing Optimizers**\n",
    "\n",
    "define studies using different optimizers to compare between:\n",
    "* Nadam\n",
    "* RMSprop\n",
    "* Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    'Nadam': Nadam,\n",
    "    'RMSprop': RMSprop\n",
    "    }\n",
    "\n",
    "optimizersStudy = dict()\n",
    "\n",
    "for opt in optimizers:\n",
    "    studyName = bestBackbone+\"_\"+opt\n",
    "    optimizersStudy[studyName] = copy.deepcopy(bestBackboneStudy[bestBackbone])\n",
    "    optimizersStudy[studyName][\"hyperparameters\"][\"optimizer\"] = optimizers[opt]\n",
    "\n",
    "optimizersHistories = utils.researchStudies(trainDs, valDs, optimizersStudy, epochsForSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizersHistories[bestBackbone+\"_Adam\"] = bestBackboneHistories[bestBackbone]\n",
    "optimizersStudy[bestBackbone+\"_Adam\"] = bestBackboneStudy[bestBackbone]\n",
    "utils.displayStudiesProgress(optimizersHistories)\n",
    "bestOptimizier = utils.getBestStudyFromHistories(optimizersHistories)\n",
    "print(bestOptimizier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparing Learning rates**\n",
    "\n",
    "define studies using different lr to compare between:\n",
    "* 0.1\n",
    "* 0.01\n",
    "* 0.001\n",
    "* 0.0001\n",
    "* 0.00001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRates = [0.1, 0.1e-1, 0.1e-3, 0.1e-4]\n",
    "\n",
    "learningRatesStudy = dict()\n",
    "\n",
    "for lr in learningRates:\n",
    "    studyName = bestOptimizier+\"_\"+str(lr)\n",
    "    learningRatesStudy[studyName] = copy.deepcopy(optimizersStudy[bestOptimizier])\n",
    "    learningRatesStudy[studyName][\"hyperparameters\"][\"learningRate\"] = lr\n",
    "\n",
    "    \n",
    "learningRatesHistories = utils.researchStudies(trainDs, valDs, learningRatesStudy, epochsForSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRatesHistories[bestOptimizier+\"_\"+str(hypers[\"learningRate\"])] = optimizersHistories[bestOptimizier]\n",
    "learningRatesStudy[bestOptimizier+\"_\"+str(hypers[\"learningRate\"])] = optimizersStudy[bestOptimizier]\n",
    "utils.displayStudiesProgress(learningRatesHistories)\n",
    "bestLearningRate = utils.getBestStudyFromHistories(learningRatesHistories)\n",
    "print(bestLearningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparing Loss Functions**\n",
    "\n",
    "define studies using different loss function to compare between:\n",
    "* binary-focal-crossentropy\n",
    "* hinge\n",
    "* binary-crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = ['binary_focal_crossentropy', 'hinge']\n",
    "\n",
    "lossStudy = dict()\n",
    "for ls in losses:\n",
    "    studyName = bestLearningRate+\"_\"+str(ls)\n",
    "    lossStudy[studyName] = copy.deepcopy(learningRatesStudy[bestLearningRate])\n",
    "    lossStudy[studyName][\"hyperparameters\"][\"loss\"] = ls\n",
    "\n",
    "lossesHistories = utils.researchStudies(trainDs, valDs, lossStudy, epochsForSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossesHistories[bestLearningRate+\"_\"+str(hypers[\"loss\"])] = learningRatesHistories[bestLearningRate]\n",
    "lossStudy[bestLearningRate+\"_\"+str(hypers[\"loss\"])] = learningRatesStudy[bestLearningRate]\n",
    "utils.displayStudiesProgress(lossesHistories)\n",
    "bestLoss = utils.getBestStudyFromHistories(lossesHistories)\n",
    "print(bestLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModelName = bestLoss\n",
    "bestModelSetting = lossStudy[bestLoss]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainValDs = trainDs.concatenate(valDs)\n",
    "bestModel = FPML(**bestModelSetting[\"architecture\"]).create(**bestModelSetting[\"hyperparameters\"])\n",
    "bestModelHistory = bestModel.fit(trainValDs, validation_data=testDs, epochs=epochsForBest, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.displayStudiesProgress({\"BestModel\\n\"+bestModelName : bestModelHistory})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.displayConfusion(testDs, bestModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel.save('./weights/'+bestModelName+'_SOCOFingers.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfmetal",
   "language": "python",
   "name": "tfmetal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
