{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import SOCOFingFingers\n",
    "from FPMLmodule.backbones import ResNet50, MobileNetV2, EfficientNetB2,ResNet101,Xception,InceptionV3\n",
    "from FPMLmodule.classifiers import ResNetClassifier, DefaultClassifier, AlexNetClassifier, MobileNetClassifier\n",
    "import FPMLmodule.utils as utils\n",
    "from FPMLmodule.fpml import FPML \n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Config\n",
    "seed=9\n",
    "img_dim = (120, 120, 3)\n",
    "img_height, img_width, img_channels = img_dim\n",
    "batch_size = 32\n",
    "\n",
    "# Dataset configuration\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "split_ratio = [0.7, 0.15, 0.15]\n",
    "shuffle=True\n",
    "dsConfig = {\n",
    "    'batchSize': batch_size, \n",
    "    'parallelTune': AUTOTUNE, \n",
    "    'split': split_ratio, \n",
    "    'inputDim': img_dim, \n",
    "    'seed': seed, \n",
    "    'shuffle': shuffle\n",
    "    }\n",
    "weightsRN50 = \"./weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "weightsMNV2 = \"./weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\"\n",
    "weightsENB2 = \"./weights/efficientnetb2_notop.h5\"\n",
    "weightsRN101 = \"./weights/resnet101_weights_tf_dim_ordering_tf_kernels.h5\"\n",
    "weightsXCEP = \"./weights/xception_weights_tf_dim_ordering_tf_kernels.h5\"\n",
    "weightsINCEV3 = \"./weights/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\"\n",
    "\n",
    "# Model Config\n",
    "learning_rate = 0.001\n",
    "epochs_find_best = 10\n",
    "epochs_best = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOCOFingers = SOCOFingFingers(**dsConfig)\n",
    "fingerDs = SOCOFingers.create()\n",
    "utils.displayDsSplit(fingerDs)\n",
    "train_ds, test_ds, val_ds = fingerDs\n",
    "# Show split by gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbClasses = len(SOCOFingers.classNames)\n",
    "activation = \"softmax\"\n",
    "\n",
    "classifiers = {\n",
    "    \"ResNet50\" : ResNetClassifier(nbClasses, activation),\n",
    "    \"AlexNet\" : AlexNetClassifier(nbClasses, activation),\n",
    "    \"Default\" : DefaultClassifier(nbClasses, activation), \n",
    "    \"MobileNetV2\" : MobileNetClassifier(nbClasses, activation)\n",
    "}\n",
    "\n",
    "backbones = {\n",
    "    \"ResNet50\" : ResNet50(img_dim, weights=weightsRN50, trainable=False),\n",
    "    \"MobileNetV2-pretrained\" : MobileNetV2(img_dim, weights=weightsMNV2, trainable=False),\n",
    "    \"MobileNetV2-trainable\": MobileNetV2(img_dim, weights=None),\n",
    "    \"ResNet101\" : ResNet101(img_dim, weights=weightsRN101, trainable=False),\n",
    "    \"EfficientNetB2\" : EfficientNetB2(img_dim, weights=weightsENB2, trainable=False),\n",
    "    \"Xception\" : Xception(img_dim, weights=weightsXCEP, trainable=False),\n",
    "    \"InceptionV3\" : InceptionV3(img_dim, weights=weightsINCEV3, trainable=False)\n",
    "    \n",
    "}\n",
    "\n",
    "optimizers = {\n",
    "    \"Adam\": Adam,\n",
    "    \"Nadam\": Nadam,\n",
    "    \"RMSProp\": RMSprop\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {\n",
    "    \"optimizer\": Adam,\n",
    "    \"learningRate\": learning_rate,\n",
    "    \"loss\": 'CategoricalCrossentropy',\n",
    "    \"metrics\": 'accuracy'\n",
    "}\n",
    "pretrainedVsFulltrainig = {\n",
    "    \"mobilenetV2-pretrained\" : {\n",
    "        \"architecture\": {\n",
    "            \"backbone\":backbones[\"MobileNetV2-pretrained\"],\n",
    "            \"classfier\":classifiers[\"MobileNetV2\"],\n",
    "            \"inputLayer\":\"\", \n",
    "            \"inputDim\": img_dim\n",
    "        },\n",
    "        \"hyperparameters\":hypers\n",
    "    },\n",
    "    \"MobileNetV2-trainable\" : {\n",
    "        \"architecture\": {\n",
    "            \"backbone\":backbones[\"MobileNetV2-trainable\"],\n",
    "            \"classfier\":classifiers[\"MobileNetV2\"],\n",
    "            \"inputLayer\":\"\", \n",
    "            \"inputDim\": img_dim\n",
    "        },\n",
    "        \"hyperparameters\":hypers\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "studies = {\n",
    "    \"resnet50\" : {\n",
    "        \"architecture\": {\n",
    "            \"backbone\":backbones[\"ResNet50\"],\n",
    "            \"classfier\":classifiers[\"ResNet50\"],\n",
    "            \"inputLayer\":\"\", \n",
    "            \"inputDim\": img_dim\n",
    "        },\n",
    "        \"hyperparameters\":hypers\n",
    "    },\n",
    "    \"efficientnetB2\": {\n",
    "        \"architecture\": {\n",
    "            \"backbone\":backbones[\"EfficientNetB2\"],\n",
    "            \"classfier\":classifiers[\"Default\"],\n",
    "            \"inputLayer\":\"\", \n",
    "            \"inputDim\": img_dim\n",
    "        },\n",
    "        \"hyperparameters\":hypers\n",
    "    },\n",
    "    \"resnet101\": {\n",
    "        \"architecture\": {\n",
    "            \"backbone\":backbones[\"ResNet101\"],\n",
    "            \"classfier\":classifiers[\"Default\"],\n",
    "            \"inputLayer\":\"\", \n",
    "            \"inputDim\": img_dim\n",
    "        },\n",
    "        \"hyperparameters\":hypers\n",
    "    },\n",
    "    \"inceptionV3\": {\n",
    "        \"architecture\": {\n",
    "            \"backbone\":backbones[\"InceptionV3\"],\n",
    "            \"classfier\":classifiers[\"Default\"],\n",
    "            \"inputLayer\":\"\", \n",
    "            \"inputDim\": img_dim\n",
    "        },\n",
    "        \"hyperparameters\":hypers\n",
    "    },\n",
    "    \"xception\": {\n",
    "        \"architecture\": {\n",
    "            \"backbone\":backbones[\"Xception\"],\n",
    "            \"classfier\":classifiers[\"Default\"],\n",
    "            \"inputLayer\":\"\", \n",
    "            \"inputDim\": img_dim\n",
    "        },\n",
    "        \"hyperparameters\":hypers\n",
    "    }\n",
    "}\n",
    "\n",
    "histories = utils.researchStudies(train_ds, val_ds, studies, 2,1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(utils.getBestStudyFromHistories(histories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "247ab06e135bb35fa78c5eff31b2a9a0050dcb5fb773c2631d2a29ac689eeccb"
  },
  "kernelspec": {
   "display_name": "tfmetal",
   "language": "python",
   "name": "tfmetal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
