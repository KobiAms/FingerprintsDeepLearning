{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.socofing import SOCOFingGender, SOCOFingFingers, SOCOFingSubjects\n",
    "from datasets import FPDataset\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import layers, Sequential, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Config\n",
    "seed=9\n",
    "img_dim = (120, 120, 3)\n",
    "img_height, img_width, img_channels = img_dim\n",
    "batch_size = 32\n",
    "\n",
    "# Dataset configuration\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "split_ratio = [0.7, 0.15, 0.15]\n",
    "shuffle=True\n",
    "dsConfig = {'batchSize': batch_size, 'parallelTune': AUTOTUNE, 'split': split_ratio, 'inputDim': img_dim, 'seed': seed, 'shuffle': shuffle}\n",
    "\n",
    "# Model Config\n",
    "learning_rate = 0.001\n",
    "epochs_find_best = 10\n",
    "epochs_best = 100\n",
    "\n",
    "\n",
    "\n",
    "print(img_dim)\n",
    "print(img_height, img_width, img_channels)\n",
    "\n",
    "genderClassNames=['F','M']\n",
    "fingersClassNames=['R_thumb', 'R_index', 'R_middle', 'R_ring', 'R_little', 'L_thumb', 'L_index', 'L_middle', 'L_ring', 'L_little ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOCOGender = SOCOFingGender(**dict(dsConfig, sampling=FPDataset.UNDER_SAMPLING))\n",
    "SOCOSubjects = SOCOFingSubjects(**dsConfig)\n",
    "SOCOFingers = SOCOFingFingers(**dsConfig)\n",
    "\n",
    "genderDS = SOCOGender.createDatasets()\n",
    "subjectDS = SOCOSubjects.createDatasets()\n",
    "fingersDS = SOCOFingers.createDatasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset split check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unionSet = set()\n",
    "interSet = set()\n",
    "sets = []\n",
    "for ds in subjectDS:\n",
    "    dsSet = set()\n",
    "    for _, labels in ds.as_numpy_iterator():\n",
    "        for label in labels:\n",
    "            parseLabel = label.decode('utf-8')\n",
    "            dsSet.add(parseLabel)\n",
    "    sets.append(dsSet)\n",
    "    unionSet = unionSet.union(dsSet) \n",
    "    interSet = interSet.intersection(dsSet) \n",
    "    \n",
    "print('Union of splitted ds subject: {}, intersaction: {}'.format(len(unionSet), len(interSet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsNames = ['SOCOGender  ', 'SOCOSubjects', 'SOCOFingers ']\n",
    "splitNames = ['train', 'test ', 'valid']\n",
    "datasets = [genderDS, subjectDS, fingersDS]\n",
    "\n",
    "data = []\n",
    "for ds in datasets:\n",
    "    data.append([len(i) for i in ds])\n",
    "\n",
    "data = []\n",
    "for ds in datasets:\n",
    "    splitLens = []\n",
    "    for split in ds:\n",
    "        splitLen = 0\n",
    "        for _, labels in split.as_numpy_iterator():\n",
    "            splitLen+=len(labels)\n",
    "        splitLens.append(splitLen)\n",
    "    data.append(splitLens)\n",
    "\n",
    "row_format =\"{:>15}\" * (len(dsNames) + 2)\n",
    "print(row_format.format(\"\", *splitNames, 'total'))\n",
    "for name, row in zip(dsNames, data):\n",
    "    print(row_format.format(name, *row, np.sum(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_from_dataset(dataset, title='', numOfImages=10, cNames=None):\n",
    "  plt.figure(figsize=(15,20))\n",
    "  plt.suptitle(title)\n",
    "  rows = int(np.ceil(numOfImages/10))\n",
    "  i=1\n",
    "  for image, label in dataset:\n",
    "    for image, label in zip(image, label):\n",
    "      \n",
    "      plt.subplot(rows, 10, i)\n",
    "      plt.axis('off')\n",
    "      plt.imshow(image, cmap='gray')\n",
    "      parseLabel = label\n",
    "      if cNames:\n",
    "        parseLabel = cNames[tf.argmax(parseLabel)]\n",
    "      plt.title(parseLabel, fontsize=16)\n",
    "      if i==numOfImages:\n",
    "        break\n",
    "      i+=1\n",
    "  plt.tight_layout()\n",
    "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "  plt.show()\n",
    "  \n",
    "train_ds, test_ds, val_ds = genderDS\n",
    "\n",
    "display_images_from_dataset(train_ds, 'Gender - Train', 100, cNames=genderClassNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Layers ###\n",
    "\n",
    "Set and initialize a classifier for five classes using fully connected layers, ReLu activation function and Dropout to increase regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_classifier = Sequential()\n",
    "fc_classifier.add(layers.Flatten())\n",
    "fc_classifier.add(layers.Dense(512, activation='relu'))\n",
    "fc_classifier.add(layers.Dropout(0.4))\n",
    "fc_classifier.add(layers.Dense(256, activation='relu'))\n",
    "fc_classifier.add(layers.Dropout(0.3))\n",
    "fc_classifier.add(layers.Dense(64, activation='relu'))\n",
    "fc_classifier.add(layers.Dropout(0.2))\n",
    "fc_classifier.add(layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50 = Sequential(\n",
    "    tf.keras.applications.ResNet50(include_top=False, input_shape=img_dim, pooling='max',classes=len(genderClassNames), weights='imagenet')\n",
    "    )\n",
    "for layer in ResNet50.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "classifier = models.clone_model(fc_classifier)\n",
    "classifier = fc_classifier.__class__.from_config(fc_classifier.get_config())\n",
    "ResNet50.add(classifier)\n",
    "ResNet50.build((None, img_height, img_width, img_channels))\n",
    "ResNet50.summary()\n",
    "ResNet50.compile(optimizer=Adam(learning_rate=learning_rate),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "ResNet50_history = ResNet50.fit(train_ds, validation_data=val_ds, epochs=epochs_find_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ResNet50_history\n",
    "acc_history = history.history['accuracy']\n",
    "val_acc_history = history.history['val_accuracy']\n",
    "loss_history = history.history['loss']\n",
    "val_loss_history = history.history['val_loss']\n",
    "fig1 = plt.gcf()\n",
    "plt.plot(acc_history)\n",
    "plt.plot(val_acc_history)\n",
    "plt.axis(ymin=0.2,ymax=1)\n",
    "plt.grid()\n",
    "plt.title('ResNet50 Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfmetal",
   "language": "python",
   "name": "tfmetal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
