{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.socofing import SOCOFingGender, SOCOFingFingers, SOCOFingSubjects\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import layers, Sequential, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOCOGender = SOCOFingGender()\n",
    "SOCOSubjects = SOCOFingSubjects()\n",
    "SOCOFingers = SOCOFingFingers()\n",
    "\n",
    "genderDSs = SOCOGender.createDatasets()\n",
    "objectsDSs = SOCOSubjects.createDatasets()\n",
    "fingersDSs = SOCOFingers.createDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_from_dataset(dataset, title='', numOfImages=9):\n",
    "  plt.figure(figsize=(13,13))\n",
    "  plt.suptitle(title)\n",
    "  subplot=331\n",
    "  for i, (image, label) in enumerate(dataset):\n",
    "    plt.subplot(subplot)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(str(label.numpy()) + \" \" +str(image.numpy().shape), fontsize=16)\n",
    "    subplot += 1\n",
    "    if i==numOfImages-1:\n",
    "      break\n",
    "  plt.tight_layout()\n",
    "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images_from_dataset(genderDSs[0], 'Gender - Train')\n",
    "display_images_from_dataset(objectsDSs[0], 'Subjects - Train')\n",
    "display_images_from_dataset(fingersDSs[0], 'Fingers - Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "PATH = './data/socofing/{}/*.BMP'\n",
    "TRAIN_PATH = PATH.format(\"train\")\n",
    "TEST_PATH = PATH.format(\"test\")\n",
    "VAL_PATH = PATH.format(\"validation\")\n",
    "CLASSES = {'M': 'male', 'F': 'female'}\n",
    "class_names = ['F', 'M']\n",
    "\n",
    "# Fixed seed for split, shuffle and init\n",
    "seed=9\n",
    "# image height and width by avvrage dataset size\n",
    "batch_size = 32\n",
    "img_dim = (180, 180, 3)\n",
    "img_height, img_width, img_channels = img_dim\n",
    "\n",
    "# model hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs_find_best = 10\n",
    "epochs_best = 100\n",
    "\n",
    "\n",
    "print(img_dim)\n",
    "print(img_height, img_width, img_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_from_dataset(dataset, title='', numOfImages=9):\n",
    "  plt.figure(figsize=(13,13))\n",
    "  plt.title(title)\n",
    "  subplot=331\n",
    "  for i, (image, label) in enumerate(dataset):\n",
    "    plt.subplot(subplot)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(str(label.numpy()) + \" \" +str(image.numpy().shape), fontsize=16)\n",
    "    subplot += 1\n",
    "    if i==numOfImages-1:\n",
    "      break\n",
    "  plt.tight_layout()\n",
    "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = FPDataset('socofing', path='./data/socofing', fileFormat='BMP', dims=img_dim, class_names=class_names)\n",
    "train_ds, test_ds, val_ds = ds.createDatasets()\n",
    "\n",
    "display_images_from_dataset(train_ds)\n",
    "\n",
    "print(train_ds, test_ds, val_ds, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_ds.take(5):\n",
    "    imageShape = image.numpy().shape\n",
    "    label = label.numpy()\n",
    "    labelName = class_names[np.argmax(label)]\n",
    "    print('Image Shape: {}, Label: {}, LabelName: {}'.format(imageShape, label, labelName))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Layers ###\n",
    "\n",
    "Set and initialize a classifier for five classes using fully connected layers, ReLu activation function and Dropout to increase regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_classifier = Sequential()\n",
    "fc_classifier.add(layers.Flatten())\n",
    "fc_classifier.add(layers.Dense(512, activation='relu'))\n",
    "fc_classifier.add(layers.Dropout(0.4))\n",
    "fc_classifier.add(layers.Dense(256, activation='relu'))\n",
    "fc_classifier.add(layers.Dropout(0.3))\n",
    "fc_classifier.add(layers.Dense(64, activation='relu'))\n",
    "fc_classifier.add(layers.Dropout(0.2))\n",
    "fc_classifier.add(layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50 = Sequential(\n",
    "    tf.keras.applications.ResNet50(include_top=False, input_shape=img_dim, pooling='max',classes=len(class_names), weights='imagenet')\n",
    "    )\n",
    "for layer in ResNet50.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "classifier = models.clone_model(fc_classifier)\n",
    "classifier = fc_classifier.__class__.from_config(fc_classifier.get_config())\n",
    "ResNet50.add(classifier)\n",
    "ResNet50.build((None, img_height, img_width, img_channels))\n",
    "ResNet50.summary()\n",
    "ResNet50.compile(optimizer=Adam(learning_rate=learning_rate),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "ResNet50_history = ResNet50.fit(train_ds, validation_data=val_ds, epochs=epochs_find_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ResNet50_history\n",
    "acc_history = history.history['accuracy']\n",
    "val_acc_history = history.history['val_accuracy']\n",
    "loss_history = history.history['loss']\n",
    "val_loss_history = history.history['val_loss']\n",
    "fig1 = plt.gcf()\n",
    "plt.plot(acc_history)\n",
    "plt.plot(val_acc_history)\n",
    "plt.axis(ymin=0.2,ymax=1)\n",
    "plt.grid()\n",
    "plt.title('ResNet50 Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfmetal",
   "language": "python",
   "name": "tfmetal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
